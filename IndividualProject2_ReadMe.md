All code needs to be written in a SINGLE .py or .java file.  Please use functions to subdivide each section in this project.  E.g., please create a function called q2 that solves all of part (2) etc.  In the end, there should be a one file called “project.py” or “project.java”.  Jupyter notebooks are not accepted.  (I want to be able to run your entire code in full at once…)

Please compress your code file along with all downloaded HTML files into a single zip file and submit that.

 

We give partial credit!  You are not required to solve everything perfectly.  If some function does not work correctly, please provide a comment in your code indicating which part of the code has hiccups.

 

Please do not use absolute paths (e.g., “/etc/profile/…” or “C:\Program Files\…”).  Please only use relative paths throughout this project.

 

 

Selenium:  The Bored Ape Yacht Club

According to Wikipedia, “[The] Bored Ape Yacht Club […] is a non-fungible token (NFT) collection built on the Ethereum blockchain.  The collection features profile pictures of cartoon apes that are procedurally generated by an algorithm.  […]  As of 2022, [Bored Ape Yacht Club’s parent company,] Yuga Labs, is valued at US$4 billion.  This is due in large part to the sales of the Bored Ape Yacht Club NFT collection totaling over US$1 billion.  Various celebrities have purchased these non-fungible tokens, including Justin Bieber, Snoop Dogg, Gwyneth Paltrow and others.”

(1)  (No programming yet,) go to https://opensea.io/collection/boredapeyachtclubLinks to an external site. and select all apes with “Solid gold” fur and sort them “Price high to low” .  Use the URL for the subsequent coding.

(2)  Using Python or Java, write code that uses Selenium to access the URL from (1), click on each of the top-8 most expensive Bored Apes, and store the resulting details page to disk, “bayc_[N].htm” (replace [N] with the ape number).

 

MongoDB

(3)  Write code that goes through all 8 htm files downloaded in (2) and stores each ape’s name (its number) and all its attributes in a document inside a MongoDB collection called “bayc”.

 

Regular Webscraping

(4)  Yellow Pages uses GET requests for its search.  Using plain Python or Java (no Selenium), write a program that searches on yellowpages.com for the top 30 “Pizzeria” in San Francisco (no need to verify that the shop is actually selling pizzas, just search for “Pizzeria”, top 30 shops according to YP's "Default" sorting).  Save the search result page to disk, “sf_pizzeria_search_page.htm”.

 

(5)  Using Python or Java, write code that opens the search result page saved in (4) and parses out all shop information (search rank, name, linked URL [this store’s YP URL], star rating If It Exists, number of reviews IIE, TripAdvisor rating IIE, number of TA reviews IIE, “$” signs IIE, years in business IIE, review IIE, and amenities IIE).  Please be sure to skip all “Ad” results.

image.png

 

MongoDB

(6)  Copy your code from (5).  Modify the code to create a MongoDB collection called “sf_pizzerias” that stores all the extracted shop information, one document for each shop.

 

Parsing

(7)  Write code that reads all URLs stored in “sf_pizzerias” and download each shop page.  Store the page to disk, “sf_pizzerias_[SR].htm” (replace [SR] with the search rank).

 

(8)  Write code that reads the 30 shop pages saved in (7) and parses each shop’s address, phone number, and website.

 

API

(9)  Sign up for a free account with https://positionstack.com/Links to an external site.  Copy your code from (8).  Modify the code to query each shop address’ geolocation (long, lat).  Update each shop document on the MongoDB collection “sf_pizzerias” to contain the shop’s address, phone number, website, and geolocation.
